---
title: "Chapter 5"
output: html_notebook
---

# 5.1 Spurious association

```{r 5.1}
# laod data
library(rethinking)
data("WaffleDivorce")
d <- WaffleDivorce

# standardise predictor
d$MedianAgeMarriage.s <- (d$MedianAgeMarriage - 
                            mean(d$MedianAgeMarriage))/
  sd(d$MedianAgeMarriage)

# fit model
m5.1 <- map(
  alist(
    Divorce ~ dnorm(mu, sigma),
    mu <- a + bA * MedianAgeMarriage.s,
    a ~ dnorm(10, 10),
    bA ~ dnorm(0, 1),
    sigma ~ dunif(0, 10)
  ),
  data = d
)

precis(m5.1)
```

```{r 5.2}
# compute percentile interval of mean
MAM.seq <- seq( from = -3, to = 3.5, length.out = 30)
mu <- link(m5.1, data = data.frame(MedianAgeMarriage.s = MAM.seq))
mu.PI <- apply(mu, 2, PI)

# plot it all
plot(Divorce ~ MedianAgeMarriage.s, data = d, col=rangi2)
abline(m5.1)
shade(mu.PI, MAM.seq)
```

```{r 5.3}
d$Marriage.s <- (d$Marriage - mean(d$Marriage))/sd(d$Marriage)
m5.2 <- map(
  alist(
    Divorce ~ dnorm(mu, sigma),
    mu <- a + bR * Marriage.s,
    a ~ dnorm(10, 10),
    bR ~ dnorm(0, 1),
    sigma ~ dunif(0, 10)
  ), data = d
)

precis(m5.2)
```

## 5.1.1 Multivariate notation
## 5.1.2 Fitting the model

```{r 5.4}
m5.3 <- map(
    alist(
        Divorce ~ dnorm( mu , sigma ) ,
        mu <- a + bR*Marriage.s + bA*MedianAgeMarriage.s ,
        a ~ dnorm( 10 , 10 ) ,
        bR ~ dnorm( 0 , 1 ) ,
        bA ~ dnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 10 )
    ) ,
    data = d )
precis( m5.3 )
```

```{r 5.5}
plot(precis(m5.3))
```

## 5.1.3 Plotting multivariate posteriors
### 5.1.3.1 _Predictor residual plots_

```{r 5.6}
m5.4 <- map(
    alist(
        Marriage.s ~ dnorm( mu , sigma ) ,
        mu <- a + b*MedianAgeMarriage.s ,
        a ~ dnorm( 0 , 10 ) ,
        b ~ dnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 10 )
    ) ,
    data = d )
```

And then we compute the _residuals_ by subtracting the observed marriage rate in each State from the predicted rate, based upon using age at marriage:
```{r 5.7}
# compute expected value at MAP, for each State
mu <- coef(m5.4)['a'] + coef(m5.4)['b']*d$MedianAgeMarriage.s
# compute residual for each State
m.resid <- d$Marriage.s - mu

```

```{r 5.8}
plot( Marriage.s ~ MedianAgeMarriage.s , d , col=rangi2 )
abline( m5.4 )
# loop over States
for ( i in 1:length(m.resid) ) {
    x <- d$MedianAgeMarriage.s[i] # x location of line segment
    y <- d$Marriage.s[i] # observed endpoint of line segment
    # draw the line segment
    lines( c(x,x) , c(mu[i],y) , lwd=0.5 , col=col.alpha("black",0.7) )
}
```

### 5.1.3.2 Counterfactual plots
```{r 5.9}
# prepare new counterfactual data
A.avg <- mean( d$MedianAgeMarriage.s )
R.seq <- seq( from=-3 , to=3 , length.out=30 )
pred.data <- data.frame(
    Marriage.s=R.seq,
    MedianAgeMarriage.s=A.avg
)

# compute counterfactual mean divorce (mu)
mu <- link( m5.3 , data=pred.data )
mu.mean <- apply( mu , 2 , mean )
mu.PI <- apply( mu , 2 , PI )

# simulate counterfactual divorce outcomes
R.sim <- sim( m5.3 , data=pred.data , n=1e4 )
R.PI <- apply( R.sim , 2 , PI )

# display predictions, hiding raw data with type="n"
plot( Divorce ~ Marriage.s , data=d , type="n" )
mtext( "MedianAgeMarriage.s = 0" )
lines( R.seq , mu.mean )
shade( mu.PI , R.seq )
shade( R.PI , R.seq )

```

```{r 5.10}
R.avg <- mean( d$Marriage.s )
A.seq <- seq( from=-3 , to=3.5 , length.out=30 )
pred.data2 <- data.frame(
    Marriage.s=R.avg,
    MedianAgeMarriage.s=A.seq
)

mu <- link( m5.3 , data=pred.data2 )
mu.mean <- apply( mu , 2 , mean )
mu.PI <- apply( mu , 2 , PI )

A.sim <- sim( m5.3 , data=pred.data2 , n=1e4 )
A.PI <- apply( A.sim , 2 , PI )

plot( Divorce ~ MedianAgeMarriage.s , data=d , type="n" )
mtext( "Marriage.s = 0" )
lines( A.seq , mu.mean )
shade( mu.PI , A.seq )
shade( A.PI , A.seq )

```

```{r 5.11}
# call link without specifying new data
# so it uses original data
mu <- link( m5.3 )

# summarize samples across cases
mu.mean <- apply( mu , 2 , mean )
mu.PI <- apply( mu , 2 , PI )

# simulate observations
# again no new data, so uses original data
divorce.sim <- sim( m5.3 , n=1e4 )
divorce.PI <- apply( divorce.sim , 2 , PI )

```

```{r 5.12}
plot( mu.mean ~ d$Divorce , col=rangi2 , ylim=range(mu.PI) ,
    xlab="Observed divorce" , ylab="Predicted divorce" )
abline( a=0 , b=1 , lty=2 )
for ( i in 1:nrow(d) )
    lines( rep(d$Divorce[i],2) , c(mu.PI[1,i],mu.PI[2,i]) ,
        col=rangi2 )
identify( x=d$Divorce , y=mu.mean , labels=d$Loc , cex=0.8 )

```

```{r 5.14, fig.height=3}
# compute residuals
divorce.resid <- d$Divorce - mu.mean
# get ordering by divorce rate
o <- order(divorce.resid)
# make the plot
dotchart( divorce.resid[o] , labels=d$Loc[o] , xlim=c(-6,5) , cex=0.6 )
abline( v=0 , col=col.alpha("black",0.2) )
for ( i in 1:nrow(d) ) {
    j <- o[i] # which State in order
    lines( d$Divorce[j]-c(mu.PI[1,j],mu.PI[2,j]) , rep(i,2) )
    points( d$Divorce[j]-c(divorce.PI[1,j],divorce.PI[2,j]) , rep(i,2),
        pch=3 , cex=0.6 , col="gray" )
}
```

```{r 5.15}
N <- 100                         # number of cases
x_real <- rnorm( N )             # x_real as Gaussian with mean 0 and stddev 1
x_spur <- rnorm( N , x_real )    # x_spur as Gaussian with mean=x_real
y <- rnorm( N , x_real )         # y as Gaussian with mean=x_real
d <- data.frame(y,x_real,x_spur) # bind all together in data frame
pairs(d)
```

```{r}
mtest <- map(
  alist(
    y ~ dnorm(mu, sigma),
    mu <-  a + b1 * x_real + b2 * x_spur,
    a ~ dnorm(10, 10),
    b1 ~ dnorm(0, 1),
    b2 ~ dnorm(0, 1),
    sigma ~ dunif(0, 10)
  ),
  data = d
)
precis(mtest)
plot(precis(mtest))
```

# 5.2 Masked relationships
```{r 5.16}
library(rethinking)
data(milk)
d <- milk
str(d)
```

```{r 5.17, eval=FALSE}
m5.5 <- map(
    alist(
        kcal.per.g ~ dnorm( mu , sigma ) ,
        mu <- a + bn*neocortex.perc ,
        a ~ dnorm( 0 , 100 ) ,
        bn ~ dnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 1 )
    ) ,
    data=d )
```

```{r}
d$neocortex.perc
```

```{r}
dcc <- d[complete.cases(d), ]
```

```{r 5.20}
m5.5 <- map(
    alist(
        kcal.per.g ~ dnorm( mu , sigma ) ,
        mu <- a + bn*neocortex.perc ,
        a ~ dnorm( 0 , 100 ) ,
        bn ~ dnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 1 )
    ) ,
    data=dcc )

precis(m5.5, digits = 3)
```

```{r 5.23}
np.seq <- 0:100
pred.data <- data.frame( neocortex.perc=np.seq )

mu <- link( m5.5 , data=pred.data , n=1e4 )
mu.mean <- apply( mu , 2 , mean )
mu.PI <- apply( mu , 2 , PI )

plot( kcal.per.g ~ neocortex.perc , data=dcc , col=rangi2 )
lines( np.seq , mu.mean )
lines( np.seq , mu.PI[1,] , lty=2 )
lines( np.seq , mu.PI[2,] , lty=2 )

```

```{r}
dcc$log.mass <- log(dcc$mass)
```

```{r 5.25}
m5.6 <- map(
    alist(
        kcal.per.g ~ dnorm( mu , sigma ) ,
        mu <- a + bm*log.mass ,
        a ~ dnorm( 0 , 100 ) ,
        bm ~ dnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 1 )
    ) ,
    data=dcc )
precis(m5.6)
```

```{r}
mass.seq <- seq(from = min(dcc$mass), 
                to = 100,
                length.out = 1e3)
pred.data <- data.frame( log.mass=log(mass.seq ))

mu <- link( m5.6 , data=pred.data , n=1e4 )
mu.mean <- apply( mu , 2 , mean )
mu.PI <- apply( mu , 2 , PI )

plot( kcal.per.g ~ log.mass , data=dcc , col=rangi2 )
lines( log(mass.seq) , mu.mean )
lines( log(mass.seq) , mu.PI[1,] , lty=2 )
lines( log(mass.seq) , mu.PI[2,] , lty=2 )

```

```{r 5.26}
m5.7 <- map(
    alist(
        kcal.per.g ~ dnorm( mu , sigma ) ,
        mu <- a + bn*neocortex.perc + bm*log.mass ,
        a ~ dnorm( 0 , 100 ) ,
        bn ~ dnorm( 0 , 1 ) ,
        bm ~ dnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 1 )
    ) ,
    data=dcc )
precis(m5.7)

```

```{r 5.27}
mean.log.mass <- mean( log(dcc$mass) )
np.seq <- 0:100
pred.data <- data.frame(
    neocortex.perc=np.seq,
    log.mass=mean.log.mass
)

mu <- link( m5.7 , data=pred.data , n=1e4 )
mu.mean <- apply( mu , 2 , mean )
mu.PI <- apply( mu , 2 , PI )

plot( kcal.per.g ~ neocortex.perc , data=dcc , type="n" )
lines( np.seq , mu.mean )
lines( np.seq , mu.PI[1,] , lty=2 )
lines( np.seq , mu.PI[2,] , lty=2 )

```

```{r}
mean.np <- mean( dcc$neocortex.perc )
mass.seq <- seq(from = min(dcc$mass), 
                to = 100,
                length.out = 1e3)
pred.data <- data.frame(
    neocortex.perc=mean.np,
    log.mass= log(mass.seq)
)

mu <- link( m5.7 , data=pred.data , n=1e4 )
mu.mean <- apply( mu , 2 , mean )
mu.PI <- apply( mu , 2 , PI )

plot( kcal.per.g ~ log.mass , data=dcc , type="n" )
lines( log(mass.seq) , mu.mean )
lines( log(mass.seq) , mu.PI[1,] , lty=2 )
lines( log(mass.seq) , mu.PI[2,] , lty=2 )

```

```{r 5.28}
N <- 100                         # number of cases
rho <- 0.7                       # correlation btw x_pos and x_neg
x_pos <- rnorm( N )              # x_pos as Gaussian
x_neg <- rnorm( N , rho*x_pos ,  # x_neg correlated with x_pos
    sqrt(1-rho^2) )
y <- rnorm( N , x_pos - x_neg )  # y equally associated with x_pos, x_neg
d <- data.frame(y,x_pos,x_neg)   # bind all together in data frame
 
pairs(d)
```

# 5.3 When adding variables hurts
## 5.3.1 Multicollinear legs
```{r 5.29}
N <- 100                          # number of individuals
height <- rnorm(N,10,2)           # sim total height of each
leg_prop <- runif(N,0.4,0.5)      # leg as proportion of height
leg_left <- leg_prop*height +     # sim left leg as proportion + error
    rnorm( N , 0 , 0.02 )
leg_right <- leg_prop*height +    # sim right leg as proportion + error
    rnorm( N , 0 , 0.02 )
                                  # combine into data frame
d <- data.frame(height,leg_left,leg_right)
```

```{r 5.30}
# m5.8 <- map(
#     alist(
#         height ~ dnorm( mu , sigma ) ,
#         mu <- a + bl*leg_left + br*leg_right ,
#         a ~ dnorm( 10 , 100 ) ,
#         bl ~ dnorm( 2 , 10 ) ,
#         br ~ dnorm( 2 , 10 ) ,
#         sigma ~ dunif( 0 , 10 )
#     ) ,
#     data=d )
# precis(m5.8)
```

```{r}
plot(precis(m5.8))
```

```{r 5.32}
post <- extract.samples(m5.8)
plot(bl ~ br, post, col=col.alpha(rangi2, 0.1), pch = 16)
```

```{r 5.33}
sum_blbr <- post$bl + post$br
dens(sum_blbr, col=rangi2, lwd = 2, xlab="sum of bl and br")
```

```{r 5.34}
m5.9 <- map(
  alist(
    height ~ dnorm(mu, sigma),
    mu <- a + bl*leg_left,
    a ~ dnorm(10, 100),
    bl ~ dnorm(2, 10),
    sigma ~ dunif(0, 10)
  ),
  data = d)
precis(m5.9)
```

## 5.3.2 Multicollinear milk
```{r 5.35}
library(rethinking)
data(milk)
d <- milk
```

```{r 5.36}
# kcal.per.g regressed on perc.fat
m5.10 <- map(
    alist(
        kcal.per.g ~ dnorm( mu , sigma ) ,
        mu <- a + bf*perc.fat ,
        a ~ dnorm( 0.6 , 10 ) ,
        bf ~ dnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 10 )
    ) ,
    data=d )

# kcal.per.g regressed on perc.lactose
m5.11 <- map(
    alist(
        kcal.per.g ~ dnorm( mu , sigma ) ,
        mu <- a + bl*perc.lactose ,
        a ~ dnorm( 0.6 , 10 ) ,
        bl ~ dnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 10 )
    ) ,
    data=d )

precis( m5.10 , digits=3 )
precis( m5.11 , digits=3 )

```

```{r 5.37}
m5.12 <- map(
    alist(
        kcal.per.g ~ dnorm( mu , sigma ) ,
        mu <- a + bf*perc.fat + bl*perc.lactose ,
        a ~ dnorm( 0.6 , 10 ) ,
        bf ~ dnorm( 0 , 1 ) ,
        bl ~ dnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 10 )
    ) ,
    data=d )
precis( m5.12 , digits=3 )
```

```{r 5.38}
pairs(~ kcal.per.g + perc.fat + perc.lactose, 
      data = d, col = rangi2)
```

```{r 5.39}
cor(d$perc.fat, d$perc.lactose)
```

## 5.3.3 Post-treatment bias
```{r 5.41}
# number of plants
N <- 100

# simulate initial heights
h0 <- rnorm(N,10,2)

# assign treatments and simulate fungus and growth
treatment <- rep( 0:1 , each=N/2 )
fungus <- rbinom( N , size=1 , prob=0.5 - treatment*0.4 )
h1 <- h0 + rnorm(N, 5 - 3*fungus)

# compose a clean data frame
d <- data.frame( h0=h0 , h1=h1 , treatment=treatment , fungus=fungus )
d
```

```{r 5.42}
m5.13 <- map(
    alist(
        h1 ~ dnorm(mu,sigma),
        mu <- a + bh*h0 + bt*treatment + bf*fungus,
        a ~ dnorm(0,100),
        c(bh,bt,bf) ~ dnorm(0,10),
        sigma ~ dunif(0,10)
    ),
    data=d )
precis(m5.13)
```

```{r 5.43}
m5.14 <- map(
    alist(
        h1 ~ dnorm(mu,sigma),
        mu <- a + bh*h0 + bt*treatment,
        a ~ dnorm(0,100),
        c(bh,bt) ~ dnorm(0,10),
        sigma ~ dunif(0,10)
    ),
    data=d )
precis(m5.14)
```

# 5.4 Cateorical variables
## 5.4.1 Binary categories

```{r 5.44}
data("Howell1")
d <- Howell1
str(d)
```

```{r 5.45}
m5.15 <- map(
  alist(
    height ~ dnorm(mu, sigma),
    mu <- a + bm*male,
    a ~ dnorm(178, 100),
    bm ~ dnorm(0, 10),
    sigma ~ dunif(0, 50)
  ),
  data = d
)
precis(m5.15)
```

```{r 5.46}
post <- extract.samples(m5.15)
mu.male <- post$a + post$bm
PI(mu.male)
```

## 5.4.2 Many categories

```{r 5.48}
data(milk)
d <- milk
unique(d$clade)
```

```{r 5.49}
(d$clade.NWM <- ifelse(d$clade == "New World Monkey", 1, 0))
```

```{r 5.50}
d$clade.OWM <- ifelse(d$clade == "Old World Monkey", 1, 0)
d$clade.S <- ifelse(d$clade == "Strepsirrhine", 1, 0)
```

```{r 5.51}
m5.16 <- map(
    alist(
        kcal.per.g ~ dnorm( mu , sigma ) ,
        mu <- a + b.NWM*clade.NWM + b.OWM*clade.OWM + b.S*clade.S ,
        a ~ dnorm( 0.6 , 10 ) ,
        b.NWM ~ dnorm( 0 , 1 ) ,
        b.OWM ~ dnorm( 0 , 1 ) ,
        b.S ~ dnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 10 )
    ) ,
    data=d )
precis(m5.16)

```

```{r 5.52}
# sample posterior
post <- extract.samples(m5.16)

# compute averages for each category
mu.ape <- post$a
mu.NWM <- post$a + post$b.NWM
mu.OWM <- post$a + post$b.OWM
mu.S <- post$a + post$b.S

# summarize using precis
precis( data.frame(mu.ape,mu.NWM,mu.OWM,mu.S) )
```

## 5.4.3 Adding regular predictor variables
## 5.4.4 Another approach: Unique intercepts

```{r 5.54}
(d$clade_ID <-  coerce_index(d$clade))
```

```{r 5.55}
# m5.16_alt <- map(
#     alist(
#         kcal.per.g ~ dnorm( mu , sigma ) ,
#         mu <- a[clade_id] ,
#         a[clade_id] ~ dnorm( 0.6 , 10 ) ,
#         sigma ~ dunif( 0 , 10 )
#     ) ,
#     data=d )
# precis( m5.16_alt , depth=2 )
```

# 5.7 Practice
Answers [here](https://rpubs.com/jmgirard/sr5)

## Easy
### 5E1
2, 3, 4

### 5E2
\begin{align}
\mu &= \alpha + \beta_{A}A_{i} + \beta_{P}P_{i} \\
\end{align}

### 5E3
\begin{align}
\mu &= \alpha + \beta_{F}F_{i} + \beta_{S}S_{i}
\end{align}

Where $F$ is amount of funding and $S$ is the size of laboratory.

Both slope parameters should be positive.

### 5E4
1, 3, 4 and 5. Easy question?

## Medium
### 5M1
Adapt from page 135

### 5M2
Adapt from page 141

### 5M3
We might hypothesize that a high divorce rate causes a higher marriage rate by introducing more unmarried individuals (who have a demonstrated willingness to marry) into the dating pool. This possibility could be evaluated using multiple regression by regressing marriage rate on both divorce rate and re-marriage rate (i.e., the rate of non-first marriages or marriages following divorces). If divorce rate no longer predicts marriage rate even when the re-marriage rate is known, this would support our hypothesis.

### 5M4
```{r}
library(tidyverse)
d <- WaffleDivorce

lds_df <- readr::read_csv("../data/raw/LDS_wiki.csv") %>% 
  select(State, LDS)
lds_df

d <- d %>% 
  dplyr::left_join(lds_df, by = c("Location" = "State"))

hist(d$LDS)
hist(log(d$LDS))

d <- d %>% 
  mutate(logLDS = log(LDS)) %>% 
  mutate(logLDS.s = (logLDS - mean(logLDS))/sd(logLDS))

hist(d$logLDS, breaks = 9)
hist(d$logLDS.s, breaks = 9)
simplehist(d$logLDS)
simplehist(d$logLDS.s)
```

Now make a new model:

```{r}
library(rethinking)
detach("package:purrr")
names(d)
m5M4 <- map(
  alist(
    Divorce ~ dnorm(mu, sigma),
    mu <- a + bR*Marriage + bA*MedianAgeMarriage + bL*logLDS.s,
    a ~ dnorm( 10 , 20 ) ,
    bR ~ dnorm( 0 , 10 ) ,
    bA ~ dnorm( 0 , 10 ) ,
    bL ~ dnorm(0, 10),
    sigma ~ dunif( 0 , 10 )
  ),
  data = d
)
precis(m5M4)
```

### 5M5
From jmgirard:
To address these two mechanisms, we need variables that would capture them. For the first mechanism, a variable corresponding to time spent exercising would be a reasonable start. For the second mechanism, a variable corresponding to frequency of eating out at restaurant would be a reasonable start. We could get even fancier and try to measure things like calories burned during exercise and calories ingested at restaurants. However, we would want to be careful not to introduce multicollinearity by adding highly correlated variables. So, I would propose the following multiple regression model:


\begin{align}
\mu_{i} = \alpha + \beta_{G}{G_i} + \beta_{E}E_{i} + \beta_{R}R_{i}
\end{align}

where $G$ represents the price of gasoline, $E$ represents one exercise-related variable, and $R$ represents one restaurant-related variable. One version of this model might use self-reported frequencies of exercise and eating out, and another version might use more rigorously measured calories burned through exercise and calories ingested from restaurants.

## Hard
```{r}
d <- read.table(
  "https://raw.githubusercontent.com/rmcelreath/rethinking/master/data/foxes.csv",
  header = TRUE,
  sep = ";")
d
summary(d)
```

### 5H1
```{r}
ma <- map(
  alist(
    weight ~ dnorm(mu, sigma),
    mu  <-a + bA * area,
    a ~ dnorm(5, 5),
    bA ~ dnorm(0, 5),
    sigma ~ dunif(0, 5)
  ),
  data = d
)

mg <- map(
  alist(
    weight ~ dnorm(mu, sigma),
    mu <- a + bG * groupsize,
    a ~ dnorm(5, 5),
    bG ~ dnorm(0, 5),
    sigma ~ dunif(0, 5)
  ),
  data = d
)

precis(ma)
precis(mg)
```

```{r}
area.seq <- seq(from = min(d$area), 
                to = max(d$area),
                length.out = 30)
mu <- link(ma, data = data.frame(area = area.seq))
```

```{r}
mu.PI <- apply(mu, 2, PI)

# plot it:
plot(weight ~ area, data = d, col = rangi2)
abline(ma)
shade(mu.PI, area.seq)
```

```{r}
gs.seq <- seq(from = min(d$groupsize),
              to = max(d$groupsize),
              length.out = 30)
mu <- link(mg, data = data.frame(groupsize = gs.seq))

mu.PI <- apply(mu, 2, PI)

# plot it
plot(weight ~ groupsize, data = d, col = rangi2)
abline(mg)
shade(mu.PI, gs.seq)
```

### 5H2
```{r}
mag <- map(
  alist(
    weight ~ dnorm(mu, sigma),
    mu <- a + ba * area + bg * groupsize,
    a ~ dnorm(5, 5),
    ba ~ dnorm(0, 5),
    bg ~ dnorm(0, 5),
    sigma ~ dunif(0, 5)
  ),
  data = d
)

precis(mag)
plot(precis(mag))
```

```{r}
# counterfactual plot for territory area
G.avg <- mean(d$groupsize)
A.seq <- seq(from = 0, to = 6, length.out = 30)
pred.data <- data.frame(
  area = A.seq,
  groupsize = G.avg
)

# compute counterfactual mean area
mu <- link(mag, data = pred.data)
mu.mean <- apply(mu, 2, mean)
mu.PI <- apply(mu, 2, PI)

# simulat counterfactual area outcomes
A.sim <- sim(mag, data = pred.data, n = 1e4)
A.PI <- apply(A.sim, 2, PI)

# display redictions, hiding raw data with type = "n"
plot(weight ~ area, data = d, type = "n")
mtext("groupsize = 4.345")

lines(A.seq, mu.mean)
shade(mu.PI, A.seq)
shade(A.PI, A.seq)
```

```{r}
# counterfacutal plot for group size
G.seq <- seq(from = 1, to = 9, length.out = 30)
A.avg <- mean(d$area)
pred.data <- data.frame(
  area = A.avg,
  groupsize = G.seq
)

# compute counterfactual mean groupsize
mu <- link(mag, data = pred.data)
```

```{r}
mu.mean <- apply(mu, 2, mean)
mu.PI <- apply(mu, 2, PI)

# simulate counterfactual groupsize outcomes
G.sim <- sim(mag, data = pred.data, n = 1e4)

```

```{r}
G.PI <- apply(G.sim, 2, PI)

# display predictions, hiding raw data with type="n"
plot(weight ~ groupsize, data = d, type="n")
mtext("area = 3.17")

lines(G.seq, mu.mean)
shade(mu.PI, G.seq)
shade(G.PI, G.seq)

```

### 5H3
```{r}
m5h3_2 <- map(
  alist(
    weight ~ dnorm(mu, sigma),
    mu <- a + bf * avgfood + bg * groupsize,
    a ~ dnorm(5, 5),
    bf ~ dnorm(0, 5),
    bg ~ dnorm(0, 5),
    sigma ~ dunif(0, 5)
  ),
  data = d
)

precis(m5h3_2)

```

```{r}
m5h3_3 <- map(
  alist(
    weight ~ dnorm(mu, sigma),
    mu <- a + bf * avgfood + bg * groupsize + ba * area,
    a ~ dnorm(5, 5),
    bf ~ dnorm(0, 5),
    bg ~ dnorm(0, 5),
    ba ~ dnorm(0, 5),
    sigma ~ dunif(0, 5)
  ),
  data = d
)

precis(m5h3_3)
```


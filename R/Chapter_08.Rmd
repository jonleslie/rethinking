---
title: "Chapter 8: Markov Chain Monte Carlo"
output: html_notebook
---

# 8.1 Good King Markov and His island kingdom

```{r 8.1}
library(rethinking)
num_weeks <- 1e5
positions <- rep(0, num_weeks)
current <- 10
for (i in 1:num_weeks) {
  # record current position
  positions[i] <- current
  
  # flip coin to generate proposal
  proposal <- current + sample(c(-1, 1), size = 1)
  # now make sure he loops arou d the archipelago
  if(proposal < 1) proposal <- 10
  if(proposal > 10) proposal <- 1
  
  # move?
  prob_move <- proposal/current
  current <- ifelse(runif(1) < prob_move, proposal, current)
}
```

```{r}
week <- 1:100
plot(week, positions[1:100], col = rangi2)
```

```{r}
visits <- as.vector(table(positions))
plot(1:10, visits)
```

# 8.3 Easy HMC: map2stan
```{r 8.2}
library(rethinking)
# https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started
data(rugged)
d <- rugged
d$log_gdp <- log(d$rgdppc_2000)
dd <- d[complete.cases(d$rgdppc_2000), ]
```

```{r 8.3}
m8.1 <- map(
  alist(
    log_gdp ~ dnorm(mu, sigma),
    mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa,
    a ~ dnorm(0, 100),
    bR ~ dnorm(0, 10),
    bA ~ dnorm(0, 10),
    bAR ~ dnorm(0, 10),
    sigma ~ dunif(0, 10)
  ),
  data = dd
)
precis(m8.1)
```

```{r 8.4}
dd.trim <- dd[,c("log_gdp", "rugged", "cont_africa")]
str(dd.trim)
```

```{r 8.5}
m8.1stan <- map2stan(
  alist(
    log_gdp ~ dnorm(mu, sigma),
    mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa,
    a ~ dnorm(0, 100),
    bR ~ dnorm(0, 10),
    bA ~ dnorm(0, 10),
    bAR ~ dnorm(0, 10),
    sigma ~ dcauchy(0, 2)
  ),
  data = dd.trim
)
```


```{r 8.6}
precis(m8.1stan)

```

```{r 8.7}
m8.1stan_4chains <- map2stan(m8.1stan, chains = 4, cores = 4)
precis(m8.1stan_4chains)
```

```{r 8.8}
# To pull out the samples
post <- extract.samples(m8.1stan)
str(post)
```

```{r 8.9}
pairs(post)
```

```{r 8.10}
pairs(m8.1stan)
```

```{r 8.11}
show(m8.1stan)
```

```{r 8.12}
plot(m8.1stan, window = c(80, 2000))
# plot(m8.1stan)
```

```{r}
stancode(m8.1stan)
```

# 8.4 Care and feeding of your Markov chain
## 8.4.1 How many samples do you need?

